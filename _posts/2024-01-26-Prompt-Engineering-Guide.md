---
title: Prompt Engineering Guide
layout: post
categories: chatgpt
tags: chatgpt
date: 2024-01-26 18:00
excerpt: Prompt Engineering Guide
---

{:.table-of-content}
* TOC
{:toc}

# [Prompt Engineering Guide](https://www.promptingguide.ai/)
提示工程是一门相对较新的学科，它致力于开发和优化提示，以高效地使用语言模型（LMs）进行广泛的应用和研究主题。掌握提示工程技能有助于更好地理解大型语言模型（LLMs）的能力和局限性。

研究人员利用提示工程提高LLMs在广泛的常见和复杂任务上的能力，例如问答和算术推理。开发者使用提示工程设计与LLMs及其他工具接口的健壮有效的提示技术。

提示工程不仅仅是关于设计和开发提示。它包含了一系列与LLMs交互和开发的有用技能和技术。这是一个重要的技能，用于与LLMs建立接口、构建及理解其能力。你可以使用提示工程来提高LLMs的安全性，并构建新的能力，如将LLMs与领域知识和外部工具增强。

受到与LLMs开发的高度兴趣的驱动，我们创建了这份新的提示工程指南，其中包含了所有最新的论文、高级提示技巧、学习指南、针对特定模型的提示指南、讲座、参考资料、新的LLMs能力和与提示工程相关的工具。

## 介绍
提示工程是一门相对较新的学科，用于开发和优化提示，以便高效地应用和构建大型语言模型（LLMs）以适应广泛的应用和用例。

掌握提示工程技能有助于更好地理解LLMs的能力和局限。研究人员使用提示工程来提高LLMs在广泛的常见和复杂任务上的安全性和能力，例如问答和算术推理。开发者使用提示工程设计与LLMs及其他工具接口的健壮有效的提示技术。

这本全面的指南涵盖了提示工程的理论和实践方面，以及如何利用最佳的提示技术与LLMs交互和构建。

所有示例均在未特别指定的情况下，使用 OpenAI 的 Playground 中的 gpt-3.5-turbo 测试。该模型使用默认配置，即温度（temperature）=1 和 top_p=1。这些提示也应该适用于具有与 gpt-3.5-turbo 类似能力的其他模型，但模型响应可能会有所不同。

### LLM配置
在设计和测试提示时，你通常会通过API与LLM进行交互。你可以配置一些参数来获得不同的提示结果。调整这些设置对于提高响应的可靠性和期望性是很重要的，并且需要一些实验才能找出适合你用例的正确设置。以下是在使用不同LLM提供商时你会遇到的常见设置：

- **温度（Temperature）**
简而言之，温度越低，结果越确定性，意味着总是会选择最可能的下一个词标（token）。提高温度可能会导致更多的随机性，这鼓励生成更多样化或有创意的输出。你本质上是在增加其他可能词标的权重。在应用方面，你可能会希望在进行基于事实的问答等任务时使用较低的温度值，以鼓励更事实性和简洁的响应。对于诗歌创作或其他创造性任务，增加温度值可能是有益的。

- **Top P**
一种与温度结合使用的采样技术，称为核心采样（nucleus sampling），你可以控制模型的确定性程度。如果你正在寻找精确和事实性的答案，保持这个值较低。如果你正在寻找更多样化的响应，可以增加到更高的值。如果使用Top P，意味着只有组成top_p概率质量的词标会被考虑到响应中，所以低top_p值会选择最有信心的响应。这意味着高top_p值将使模型考虑更多可能的词，包括不太可能的词，从而导致更多样化的输出。一般建议是改变温度或Top P，但不要同时改变。

- **最大长度（Max Length）**
你可以通过调整最大长度来管理模型生成的词标数量。指定最大长度可以帮助你防止长或不相关的响应，并控制成本。

- **停止序列（Stop Sequences）**
停止序列是一个停止模型生成词标的字符串。指定停止序列是另一种控制模型响应长度和结构的方式。例如，你可以告诉模型生成的列表最多不超过10项，通过添加“11”作为停止序列。

- **频率惩罚（Frequency Penalty）**
频率惩罚根据下一个词标在响应和提示中出现的次数对其施加惩罚。频率惩罚越高，一个词重复出现的可能性就越小。这个设置通过对出现更多次的词标给予更高的惩罚，减少了模型响应中的词重复。

- **存在惩罚（Presence Penalty）**
存在惩罚也对重复的词标施加惩罚，但与频率惩罚不同的是，所有重复的词标受到相同的惩罚。出现两次和出现十次的词标受到相同的惩罚。这个设置防止模型在其响应中过于频繁地重复短语。如果你希望模型生成多样化或有创意的文本，你可能会想使用更高的存在惩罚。或者，如果你需要模型保持专注，尝试使用较低的存在惩罚。

与温度和top_p相似，一般建议是改变频率或存在惩罚，但不要同时改变。

在开始一些基本示例之前，请记住，你的结果可能会因使用的LLM版本而有所不同。

### 提示基础
#### 向LLM发出提示
你可以通过简单的提示来实现很多事情，但结果的质量取决于你提供了多少信息以及提示的制作有多精良。一个提示可以包含像你传递给模型的指令或问题这样的信息，并包括其他细节，如上下文、输入或示例。你可以使用这些元素来更有效地指导模型，以提高结果的质量。

让我们开始，通过一个简单提示的基本示例来入门：

Prompt：
```
The sky is
```

Output：
```
blue.
```

如果你正在使用OpenAI Playground或任何其他LLM playground，你可以像下面的屏幕截图所示提示模型：
![](/assets/img/llm_prompt/sky.webp)

需要注意的是，当使用OpenAI的聊天模型，如gtp-3.5-turbo或gpt-4时，你可以使用三种不同的角色来构建你的提示：系统（system）、用户（user）和助手（assistant）。系统消息并非必需，但有助于设定助手的整体行为。上述示例只包括一个用户消息，你可以使用它直接提示模型。为了简单起见，除非明确提到，所有的示例都将仅使用用户消息来提示gpt-3.5-turbo模型。上述示例中的助手消息对应于模型的响应。你也可以定义一个助手消息来传递你所希望的期望行为的示例。你可以在[这里](https://www.promptingguide.ai/models/chatgpt)了解更多关于与聊天模型合作的信息。

从上面的提示示例中你可以观察到，语言模型根据上下文“天空是”响应了一系列有意义的词标。输出可能是出乎意料的，或者与你想要完成的任务相去甚远。实际上，这个基本示例突显了提供更多上下文或关于你具体想要通过系统实现什么的指示的必要性。这正是提示工程的全部内容。

让我们尝试改进一下：

Prompt：
```
Complete the sentence: 
The sky is
```

Output：
```
blue during the day and dark at night.
```

这样更好吗？嗯，通过上述提示，你指导模型完成了句子，所以结果看起来好多了，因为它完全按照你告诉它的去做了（"完成这个句子"）。这种设计有效提示以指导模型执行期望任务的方法，就是本指南中所说的提示工程。

上面的示例是一个基本的说明，展示了当今LLM能够做到的事情。如今的LLM能够执行各种高级任务，这些任务范围从文本摘要到数学推理，再到代码生成。

#### 格式化提示
你在上面尝试了一个非常简单的提示。一个标准的提示有以下格式：
```
<Question>?
```
或
```
<Instruction>
```

你可以将其格式化为问答（QA）格式，这在很多QA数据集中是标准格式，如下所示：
```
Q: <Question>?
A: 
```

当像上面那样提示时，这也被称为零次提示（zero-shot prompting），即你直接请求模型响应，而不提供任何有关你希望它完成的任务的例子或演示。一些大型语言模型有能力进行零次提示，但这取决于手头任务的复杂性和知识，以及模型被训练得擅长执行的任务。

一个具体的提示示例如下：

Prompt：
```
Q: What is prompt engineering?
```

对于一些较新的模型，你可以跳过“Q:”部分，因为基于序列的构成，模型会隐含地理解这是一个问答任务。换句话说，提示可以简化如下：

Prompt：
```
What is prompt engineering?
```

根据上面的标准格式，一种流行且有效的提示技术被称为少次示例提示（few-shot prompting），在这种方式中，你提供示例（即演示）。你可以按照以下方式格式化少次示例提示：

```
<Question>?
<Answer>
<Question>?
<Answer>
<Question>?
<Answer>
<Question>?
```

QA版本格式如下：

```
Q: <Question>?
A: <Answer>
Q: <Question>?
A: <Answer>
Q: <Question>?
A: <Answer>
Q: <Question>?
A:
```

请记住，使用问答格式并不是必需的。提示的格式取决于当前的任务。例如，你可以执行一个简单的分类任务，并提供示例来展示任务，如下所示：

Prompt：
```
This is awesome! // Positive
This is bad! // Negative
Wow that movie was rad! // Positive
What a horrible show! //
```

Output：
```
Negative
```

少次示例提示（few-shot prompts）使得在上下文中学习成为可能，这是指语言模型在给定几个演示后学习任务的能力。我们将在接下来的章节中更广泛地讨论零次提示（zero-shot prompting）和少次示例提示（few-shot prompting）。