---
title: Fuzzing A survey
layout: post
categories: fuzz
tags: fuzz
date: 2021-04-28 10:00
excerpt: Fuzzing A survey
---

# Fuzzing: A survey
![](/assets/img/fuzzing.jpg)

{:.table-of-content}
* TOC
{:toc}

## 引言 (Introduction)

Fuzzing一直是一种高效的漏洞挖掘方法，自从AFL横空出世以来，Fuzzing技术得到了更加广泛的关注和普及，关于Fuzzing的论文也层出不穷，本文旨在对这些Fuzz技术做一个概括性的回顾，限于本人的水平，存在大量疏漏是在所难免的。先推荐两篇Fuzzing的综述：

* [The art science and engineering of fuzzing a survey](https://arxiv.org/pdf/1812.00140.pdf)
* [Fuzzing: state of art](https://wcventure.github.io/FuzzingPaper/Paper/TRel18_Fuzzing.pdf)

## 定义 (Definition)

什么是Fuzzing？Fuzzing实际上就是程序测试的一种，但与其他测试不同的是，Fuzzing主要用来测试程序的安全问题，它可以分为以下三类：

* **白盒 (White-box Fuzzer)**<br>
白盒Fuzzer通过分析程序的源码得到尽可能多的关于程序的信息，然后尝试遍历程序中所有的路径，使用的技术通常为符号执行(Symbolic Execution)，性能比其他两种类型的Fuzzer要差一些。

* **黑盒 (Black-box Fuzzer)**<br>
黑盒Fuzzer不关心程序内部的信息，把程序当作一个黑箱，只处理输入输出，运行性能最高，但由于缺少程序运行逻辑的信息，发现漏洞的效率会很快达到瓶颈。通常使用人工来改善黑盒Fuzzer的效率，比如人工编写模板、修改测试用例等等。

* **灰盒 (Grey-box Fuzzer)**<br>
灰盒Fuzzer结合了白盒和黑盒的思想，为了保证执行速度，灰盒Fuzzer只从程序中获取一部分信息来指导Fuzzing的进行，通常会使用程序运行的覆盖度信息。

## 设计 (Design)

Fuzzer的设计总体上十分简单，包括一个被测试的程序、一个输入生成器，一个信息采集器和一个Bug监测器，输入生成器产生大量的输入喂给被测程序，信息采集器收集程序运行的信息反馈给输入生成器以便使它能够生成更加有效的输入，而Bug监测器则监控程序是否会产生安全问题。关于Fuzz执行的流程可参考[Fuzzing平台建设的研究与设计](https://security.tencent.com/index.php/blog/msg/143)。Now let's take a closer look at Fuzzing Techniques：

### 环境准备 (Environment Preparation)

* **种子样本 (Seed Corpus)**<br>
Fuzzer最重要的就是要产生各种各样的输入，输入的生成主要有两种方式，一是人工编写模板，定义Structure或Grammar，然后根据定义的Structure或Grammar来生成输入。比如要测试word程序，如果让word打开随机生成的文件，大部分情况都会直接报错退出，无法深入的测试下去。要解决这个问题，天然的想法就是分析doc文件的格式，然后按照doc的格式生成文件，并在其中的某些部分加一些随机或自定义数据。但人工编写模板有一个缺陷，它需要大量人力的投入，所以另外一种方式就是找一些正常的doc文件，然后随机的变动其中的一部分内容，把新生成的文件作为输入让word程序加载。对于种子样本的选择需要十分留意，它会极大的影响到Fuzzer的效率，还以word为例，如果选择的种子都是只包含文字的doc文档，无论对它们做怎样的改变，都很难测试到word程序对各种图像、表格等富文本内容的解析。

* **移植样本 (Sample Transplant)**<br>
如果测试的程序是闭源软件，动态插桩的运行速度较慢，即无法高效的从运行的程序中收集信息，那么可以采用曲线救国的方式，选择一个同功能的开源软件，对它进行Fuzzing，收集有效样本，然后把这些样本应用于这个闭源软件。可以参考projectzero的一篇博客[a year of windows kernel font fuzzing](https://googleprojectzero.blogspot.com/2016/07/a-year-of-windows-kernel-font-fuzzing-2.html)。

* **驱动程序 (Fuzz Driver)**<br>
如果Fuzzing的对象为一个库，无法直接运行，那么就需要编写一个使用该库的程序 (harness)，然后对这个程序进行Fuzzing。显而易见，编写Harness十分关键，假如被测试的库中包含100个函数，而编写的程序中只用到了其中10个，可想而知它的效果一定不好。但编写harness也是一个需要大量人力投入的工作，需要测试人员对被测试库十分的熟悉，为了解决这个问题，Google员工开发了一个[FUDGE](https://wcventure.github.io/FuzzingPaper/Paper/FSE19_FUDGE.pdf)用来自动生成harness。它的核心思想是利用公司的代码仓库，从中抽取出使用该库的代码，然后组装拼接成可执行的测试程序。

* **最小集 (Minset)**<br>
不同的测试样本对被测程序的影响是不同的，有的样本会比其他样本覆盖到更多的程序代码，例如包含文字和图片的doc文件就会比只包含文字的doc文件覆盖到更多的word代码。由于Fuzzer会对每一个样本做mutation，如果这个样本本身就不够好，那么对它做mutation就浪费时间了，因此需要找到一个度量样本效果的方法。我们定义C(a)为被测程序P在运行样本a时所执行的指令集合，如果C(a)包含C(b)，那么样本a包含样本b。现有样本集F，C(F)为F产生的所有指令集，那么最小集S是这样一个集合，它是F的一个子集，任选样本x属于S，都不存在y属于S，y包含x，并且C(S)等于C(F)。根据定义，最小集的覆盖度等于全部集合的覆盖度，那么只对最小集做变异即可，无需管剩下的样本，节省了很多无用功。关于最小集的算法可以参考[Optimizing Seed Selection for Fuzzing](https://www.usenix.org/system/files/conference/usenixsecurity14/sec14-paper-rebert.pdf)和其[测试集](https://security.ece.cmu.edu/coverset/)。

* **局部测试 (Partial Fuzz)**<br>
当Fuzz对象十分庞大时，比如adobe reader，我们不想对这个程序的整体进行fuzz，只想针对性的测试解析pdf的部分，这时就要对它进行分析，找到解析pdf对应的函数在哪个库中，然后自己写一个harness直接调用这个库，例如[fuzzing adobe reader](https://kciredor.com/fuzzing-adobe-reader-for-exploitable-vulns-fun-not-profit.html)。如果就想测试主程序中的一部分代码，也可以使用[LIEF](https://github.com/lief-project/LIEF)把可执行程序转成库，然后编写测试程序调用该库中的函数。如果fuzz的对象为一个后台服务，比如windows service，fuzz程序不方便作为它的父进程，这时可以利用动态插桩工具在目标程序的两个点之间反复执行，即In-memory Fuzzing，可以参考[winafl_inmemory](https://github.com/s0i37/winafl_inmemory)。

* **运行优化 (Executing Optimization)**<br>
由于Fuzzer通常需要反复启动被测试程序，会带来一定的性能消耗，为此afl-fuzz采用了[fork server](https://lcamtuf.blogspot.com/2014/10/fuzzing-binaries-without-execve.html)的技术来保证被测程序一直在内存中，还有人对fork系统调用进行了优化，进一步提高性能[Improve
Fuzzing Performance](https://gts3.org/assets/papers/2017/xu:os-fuzz.pdf)、[代码](https://github.com/sslab-gatech/perf-fuzz)。此外，在内存够用的情况下，可以把被测程序和需要用到的样本都放在内存文件系统中(如：tmpfs)，当样本不再有用，就可以换出到硬盘上，换入新的样本。如果使用虚拟机对系统内核进行fuzz，也可以使用snapshot来减少虚机启动的时间。

### 反馈驱动 (Feedback Driving)

* **虚拟化反馈 (virtualized Feedback)**<br>
当对测试目标和所运行的系统有充分了解时，可通过虚拟化或驱动的方式对系统的运行进行干预(hook、monitor、poison...)，有针对性的检测特定类型的Bug而无需产生崩溃，例如[digtool](https://www.usenix.org/system/files/conference/usenixsecurity17/sec17-pan.pdf)、[bochspwn](https://j00ru.vexillium.org/papers/2018/bochspwn_reloaded.pdf)，它们通过对系统内核内存访问的监控来发现信息泄露等Bug。由于监控内核的运行需要耗费很多的性能，还有人提出了通过snapshot + replay with modification的优化方案[Differential Replay](http://yajin.org/papers/ccs19_timeplayer.pdf)。

* **覆盖度反馈 (Coverage Feedback)**<br>
覆盖度反馈的一个典型代表就是[afl-fuzz](https://lcamtuf.coredump.cx/afl/technical_details.txt)，它通过对程序的插桩来收集运行时的覆盖度信息。程序最基本的运行单位是基本块(Basic Block)，即不包含任何跳转的执行块，对基本块中的每一条指令，逻辑上都是按顺序依次执行的。当发生跳转时，就会形成新的基本块，从这个基本块跳到新的基本块，构成了一个有向图，即CFG(Control Flow Graph。覆盖度采集器对目标程序的插桩(Instrument)就是在每一个基本块中插入自定义的代码，记录该基本块是否被执行到，或者连接两个基本块的边是否被执行到。例如，我们可以定义B(a)为程序运行样本a时所有执行过的基本块集合，如果存在基本块x属于B(b)但不属于B(a)，那么样本b相对于样本a就产生了新的覆盖度，样本b为新生成的有效样本，反之如果样本b没有产生新的覆盖度，那它就是无效样本。覆盖度反馈的目的，就是淘汰掉不能产生新覆盖度的样本，即把遗传算法和覆盖度信息结合起来运用。首先有一些初始样本(初始种群)，然后计算覆盖度(个体适应度)，如果样本无法产生新的覆盖度，就淘汰它(无法适应环境生存)，之后从留下的样本中选择一个样本进行变异，计算新产生的变异样本的覆盖度(个体适应度)，判断其是淘汰还是留下，如此反复。afl-fuzz是记录的边覆盖度，如果CFG中有一条新的边被覆盖到，那么就认为是产生了新的覆盖度。

  * **插桩 (Instrument)**<br>
  插桩分为静态插桩和动态插桩两种，静态插桩需要源代码，在编译源码时进行插桩，运行速度比动态插桩要快很多，gcc、clang等编译器都支持插桩功能。在没有源码的情况下，为了追求和静态插桩同样的性能，还可以使用binary rewrite的技术，利用DynInst、Syzygy等工具重写二进制文件。binary rewrite实际上就是把机器码反编译为IR(中间语言)，然后对IR进行插桩，再编译为机器码，这个过程会带来不确定性，比如对机器码的反编译就无法100%准确，所以在没有源码的情况下，更通用的方法是使用动态插桩，即通过虚拟cpu(cpu emulator)的方式执行代码，并在执行过程中添加自定义指令，如DynamoRIO、PIN、QEMU。但虚拟cpu和物理cpu还是存在一些[区别](http://roberto.greyhats.it/pubs/issta09.pdf)，所以最好使用Intel新的支持intel PT的cpu，使用cpu自带的功能来进行插桩。

  * **AFL优化 (AFL Optimization)**<br>
  由于afl-fuzz的广泛流行，不断有人在它的基础上进行优化，还有人把这些优化都集成在了一起，例如[afl++](https://aflplus.plus//papers/aflpp-woot2020.pdf)。

    * **结构变异 (Structure Mutation)**<br>
    AFL的变异策略属于全盲变异，即在不知道输入格式的情况下，随机选取input中的部分内容进行变异。AFL之所以比其他黑盒fuzzer效率要高很多，不在于它的变异方式，而是在于覆盖度反馈机制，虽然是全盲变异，但是可以通过覆盖度反馈来决定此次变异是否有效(增加覆盖度即为有效)。就跟自然界一样，通过随机的基因突变产生不同的后代，如果能适应环境则生存(带来新的覆盖度)，不能则淘汰，如此反复的迭代，慢慢进化出更好的后代。但是用覆盖度作为适者生存的条件还太宽泛，信息量不够，对于复杂的文件格式或者协议就很难达到很好的效果，例如常见的图片格式PNG，它包含了一个对数据的校验信息(checksum)，如果校验不通过，则直接失败退出，所以需要fuzzer在每一次变异之后都要重新计算校验值，否则就会因为校验值总是不对而无法得到新覆盖度。它的解决方法有两种，一种是改代码，如果解析png的软件是开源的，就可以注释掉检查校验的函数，另一种方法就是使用AFL提供的postprocessor在变异之后自行计算校验值。后来有人又为AFL加入了custom mutator接口，也有人为AFL添加了对bt描述文件(010 Editor)的支持，如[FormatFuzzer](https://uds-se.github.io/FormatFuzzer/)，对pit描述文件(Peach)的支持，如[AFLSmart](https://mboehme.github.io/paper/TSE19.pdf)。

    * **策略调度 (Strategy Scheduling)**<br>
    下图中显示了AFL内置的Mutator，AFL在fuzz时会先按顺序执行各种mutator，即deterministic stage，之后会进入havoc stage，即不断随机选择一种方式进行变异，最后进入splicing stage，即随机选择一个样本与当前样本进行交叉变异。首先被质疑的就是deterministic stage，觉得它效率太低，AFL花了太多的时间在这个阶段，并且不同的mutator的效果是不一样的，AFL把大量的时间用在了低效的mutator上面，[MOpt](https://www.usenix.org/system/files/sec19-lyu.pdf)使用了粒子群优化算法(Particle Swarm Optimization)，主要应用在havoc stage，它把所有的Mutator当作一个粒子群，用产生的有效样本和独立崩溃数之和来度量Mutator的效果，通过粒子群优化算法来调整每种Mutator的优先级(通过select_algorithm函数选择)，为了计算全局最优值，它使用了5个swarm。此外，当Fuzzer产生的变异样本不断增加时，如何选择更为有效的样本进行变异就成了问题，AFL的一个问题就是很多路径会被反复的Fuzz到，而有些路径则很少会被Fuzz，天然的想法就是给那些能够覆盖到这些较少被fuzz到的路径的样本更高的优先权，例如[AFLFast](https://www.comp.nus.edu.sg/~abhik/pdf/CCS16.pdf)和[FairFuzz](https://arxiv.org/pdf/1709.07101.pdf)。但本质上这些改进都是锦上添花，解决了Boosting的问题，初期看起来更高效，但运行一段时间后都会和AFL一样遇到瓶颈，无法发现新路径。导致这个问题的核心就在于覆盖度反馈的信息量不够，基于这个信息量再怎么优化都有瓶颈，要想解决它，只能获取更多的信息用来指导Fuzzing，如符号执行或污点追踪。<br>
    ![](/assets/img/afl_mutator.png)

    * **比较展开 (Compare Expansion)**<br>
    对于全盲变异来说，如何能够高效的跨过比较语句的门槛是一个很重要的课题，比如对于 if(a == 0xabcdef) 或者 strcmp(a, "helloworld") 这类语句，如何成功的执行过去。解决方法也比较直接，在有源码的情况下，通过插桩的方式把多字节比较变为单字节比较，例如：[Circumventing Fuzzing Roadblocks with Compiler Transformations](https://lafintel.wordpress.com/2016/08/15/circumventing-fuzzing-roadblocks-with-compiler-transformations/)。

    * **规模扩张 (Scale Expansion)**<br>
    AFL本身支持分布式Fuzzing，但同步的方式比较原始，不同的fuzzer之间直接同步各自的样本，每个fuzzer都会跑一遍其他fuzzer所生成的样本，带来了极大的性能损耗，因为其他fuzzer产生的大部分样本可能都无法给自己带来新的覆盖度，所以在同步样本时应该再同步一份该样本对应的覆盖度信息，fuzzer不用执行样本，只需检查覆盖度信息就可判断出该样本是否有用，这在前面的运行优化中提到的论文里面也有实现[Improve Fuzzing Performance](https://gts3.org/assets/papers/2017/xu:os-fuzz.pdf)。

    * **样本选择（Seed Scheduling）
    当有众多样本时，选择哪个样本进行变异就成了问题，理想状态是优先选择可能产生最多新路径的样本。比较直接的想法是选择过去产生覆盖度最多的样本，或者覆盖到最多稀有路径的样本来进行变异，但都不够准确。[K-Scheduler](https://arxiv.org/pdf/2203.12064.pdf)提出了一种基于CFG的改进方案，首先在CFG中标记出访问和未访问的节点，找出那些父节点是已访问的未访问节点（horizon node），然后根据horizon node所能带来的新路径数为其计算出一个分值，最后把样本和horizon node进行关联（若样本的覆盖节点包含horizon node的父节点），根据horizon node的分值计算样本的分值，选择最高分值的样本进行变异。
    
    * **其他 (Others)**<br>
    如果程序中的比较条件里所使用的数据直接来自于程序输入，[RedQueen](https://www.syssec.ruhr-uni-bochum.de/media/emma/veroeffentlichungen/2018/12/17/NDSS19-Redqueen.pdf)提出了一种自动化锁定比较条件对应的数据在输入中的位置，然后解决它的方案，但在有了比较展开的情况下，这个就不太需要了。由于AFL是用map来记录边的覆盖度信息，会产生hash碰撞，[CollAFL](https://chao.100871.net/papers/oakland18.pdf)通过改进hash的计算方法来缓解碰撞的问题，但在有源码的情况下可以直接用llvm提供的trace_pc_guard就行了。AFL只记录边的一阶覆盖度信息(基于当前基本块往前回溯一个基本块)，也有人提出可以丰富覆盖度记录的信息，例如记录n阶边的信息(基于当前基本块往前回溯n个基本块)，或者记录对内存地址的访问信息等等，如[N-Gram Branch Coverage](https://www.usenix.org/system/files/raid2019-wang-jinghan.pdf)。

### 动态符号执行 (Dynamic Symbolic Execution)

符号执行把程序的输入进行符号化，程序的每一个分支都会被分解为两个分支，true branch and false branch，每个分支都对应一个基于上述符号的公式，一条路径为可达路径当且仅当输入满足路径分支上的所有公式，即给定一条路径，可以通过计算(SMT solver)来求解对应的输入。但由于路径爆炸、系统调用等问题导致符号执行的效果较差，所以它一直只停留在学术领域，很少被实际应用。后来发展出了一种对符号执行的改进，即动态符号执行，也叫做concolic (concrete + symbolic) fuzzing，即使用固定的执行状态(已知输入)来降低符号执行的复杂度，比如在DARPA举办的Cyber Grand Challenge比赛中就使用了动态符号执行，如[Driller](https://www.cs.ucsb.edu/~vigna/publications/2016_NDSS_Driller.pdf)、[Cyberdyne](https://github.com/trailofbits/publications/blob/master/papers/cyberdyne.pdf)。关于符号执行更具体一些的介绍可参见[符号执行技术总结](https://zhuanlan.zhihu.com/p/56332152)，[符号执行研究综述](https://docs.google.com/presentation/d/1E3uE-4mYpenw0s40rtMbIdxj3fJgC79aHCeiIlJSY5Y/edit#slide=id.p)。

### 污点分析 (Taint Analysis)

污点分析技术首先标记哪些数据是污点需要被追踪，而后分析污点数据在程序中的传播，如果把输入标记为污点，就可以分析程序的某个分支依赖于输入的哪部分数据，通过针对性的变异这部分数据来改变分支的走向，最简单的方式是通过随机变异，[Angora](https://arxiv.org/pdf/1803.01307.pdf)提出了使用梯度下降的方式来改进变异策略。google也准备在它的oss-fuzz中集成污点分析的功能[DFT](https://github.com/google/oss-fuzz/issues/1632)。污点分析的原理可参考[污点分析介绍](https://github.com/firmianay/CTF-All-In-One/blob/master/doc/5.5_taint_analysis.md)，

### 问题检测 (Bug Oracle)

Fuzzing的目的是检测安全问题，例如缓冲区溢出、信息泄露、释放后重用等等，基本上都是内存使用不当的问题，为了检测这类问题，就需要对程序使用内存的行为做监测，如分配内存、释放内存、引用内存等等。对于开源软件，可以使用插桩的方法进行检测，如[Sanitizers](https://github.com/google/sanitizers)。对于闭源软件，可以使用AFL提供的libdislocator，原理类似windows的PageHeap，在分配内存的时候额外分配一个保护页，当越界访问到保护页时就会导致程序崩溃。由于libdislocator功能有限，有人就使用qemu来辅助进行内存检测[QAsan](https://andreafioraldi.github.io/assets/qasan-secdev20.pdf)。详细的内存Bug分类和其检测方法可以参考这篇综述文章[Sanitizing for Security](https://arxiv.org/pdf/1806.04355.pdf)。

### 分布式Fuzzing (Distribute Fuzzing)

除了上述AFL的依靠同步各个fuzzer的有效样本进行分布式Fuzzing之外，实现得比较好的就是[syzkaller](https://github.com/google/syzkaller)，它主要分manager和fuzzer两部分，各个fuzzer发现的新样本都会同步给manager，同时fuzzer也会从manager那拉取其他fuzzer产生的新样本，目前好像还没有开源的、具有同样功能的、工程化像syzkaller一样好的针对用户态应用程序的fuzzer。syzkaller是针对内核的Fuzzing工具，应该算是目前最好的内核Fuzzer了吧，内核Fuzz与应用程序Fuzz不同，它主要是针对syscall进行测试，syzkaller目前在生成testcase时没有对各个syscall之间的联系做处理，[moonshine](https://www.cs.columbia.edu/~suman/docs/moonshine.pdf)通过对strace收集到信息生成更加有效的样本集。

## 尾声 (Finale)

关于Fuzz就介绍到这里，有很多的内容都没有涉及到，比如这里只讲了用于发现内存漏洞的Fuzz技术，其他类型的漏洞就没有涉及，并且内存漏洞往往也不是用起来最简便的，需要bypass各种各样的缓解措施。Fuzzing技术的主要目的就是尽可能的去除人工，自动化的发现漏洞，但如果是作为漏洞挖掘人员，那么就要思考如何把自己对于Fuzz目标的理解和对漏洞的理解等等这些知识利用进去。本文的目的主要是介绍一些Fuzz技术，对于Fuzzer就不过多的讲了，因为很多fuzzer自己也没用过，不好评价，AFL++和syzkaller都用过也都不错。其他还有一些专门的非通用的fuzzer，比如有个人在google summer code里提交了一个针对qemu虚拟设备的[fuzzer](https://www.youtube.com/watch?v=2PRGlLoUpLs)，已经被合并到了qemu的代码中，虽然没用过，但看了看感觉还是不错的，发现了很多Bug。还有一些其他的，如[js fuzzer](https://github.com/fuzzitdev/jsfuzz)、[java fuzzer](https://github.com/rohanpadhye/JQF)、[go fuzzer](https://github.com/dvyukov/go-fuzz)、[python fuzzer](https://github.com/google/atheris)等等。特别值得一提的就是google的[oss-fuzz](https://github.com/google/oss-fuzz)，集成了很多开源软件的fuzzer，运行在google的集群上，为开源软件安全性的提高做出了很大的贡献。
